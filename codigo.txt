            if current_page_num < i:
                browser.find_element(By.XPATH, value='//*[@id="primary_column"]/footer/div/div/div/nav/span[2]/a').click()
            elif current_page_num > i:
                browser.find_element(By.XPATH, value='//*[@id="primary_column"]/footer/div/div/div/nav/span[1]/a').click()
            else:
                break
                
-----------------------------------------------------------------------------------------------------------

            hyperlink_li_tag = li_tags[0]

            temp_list.append("https://exoplanets.nasa.gov"+ hyperlink_li_tag.find_all("a", href=True)[0]["href"])

------------------------------------------------------------------------------------------------------
    try:
        page = requests.get(hyperlink)      
        soup = BeautifulSoup(page.content, "html.parser")
        temp_list = []
        
-----------------------------------------------------------------
        for tr_tag in soup.find_all("tr", attrs={"class": "fact_row"}):
            td_tags = tr_tag.find_all("td")
          
            for td_tag in td_tags:
                try: 
                    temp_list.append(td_tag.find_all("div", attrs={"class": "value"})[0].contents[0])
                except:
                    temp_list.append("")
                    
        new_planets_data.append(temp_list)
        
-------------------------------------------------------------------------------------------------------
    except:
        time.sleep(1)
        scrape_more_data(hyperlink) 
        
--------------------------------------------------------------------------
    print(row['hyperlink'])
    scrape_more_data(row['hyperlink'])
    
---------------------------------------------------------------------
    for el in row: 
        el = el.replace("\n", "")
        replaced.append(el)
        
----------------------------------------------------------------
